{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\n\nclass LayerNormalization(nn.Module):\n\n    def __init__(self, features: int, eps:float=10**-6) -> None:\n        super().__init__()\n        self.eps = eps\n        self.alpha = nn.Parameter(torch.ones(features)) # alpha is a learnable parameter\n        self.bias = nn.Parameter(torch.zeros(features)) # bias is a learnable parameter\n\n    def forward(self, x):\n        # x: (batch, seq_len, hidden_size)\n         # Keep the dimension for broadcasting\n        mean = x.mean(dim = -1, keepdim = True) # (batch, seq_len, 1)\n        # Keep the dimension for broadcasting\n        std = x.std(dim = -1, keepdim = True) # (batch, seq_len, 1)\n        # eps is to prevent dividing by zero or when std is very small\n        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n\nclass FeedForwardBlock(nn.Module):\n\n    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n        super().__init__()\n        self.linear_1 = nn.Linear(d_model, d_ff) # w1 and b1\n        self.dropout = nn.Dropout(dropout)\n        self.linear_2 = nn.Linear(d_ff, d_model) # w2 and b2\n\n    def forward(self, x):\n        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\n\nclass InputEmbeddings(nn.Module):\n\n    def __init__(self, d_model: int, vocab_size: int) -> None:\n        super().__init__()\n        self.d_model = d_model\n        self.vocab_size = vocab_size\n        self.embedding = nn.Embedding(vocab_size, d_model)\n\n    def forward(self, x):\n        # (batch, seq_len) --> (batch, seq_len, d_model)\n        # Multiply by sqrt(d_model) to scale the embeddings according to the paper\n        return self.embedding(x) * math.sqrt(self.d_model)\n    \nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n        super().__init__()\n        self.d_model = d_model\n        self.seq_len = seq_len\n        self.dropout = nn.Dropout(dropout)\n        # Create a matrix of shape (seq_len, d_model)\n        pe = torch.zeros(seq_len, d_model)\n        # Create a vector of shape (seq_len)\n        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n        # Create a vector of shape (d_model)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n        # Apply sine to even indices\n        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n        # Apply cosine to odd indices\n        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n        # Add a batch dimension to the positional encoding\n        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n        # Register the positional encoding as a buffer\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n        return self.dropout(x)\n\nclass ResidualConnection(nn.Module):\n    \n        def __init__(self, features: int, dropout: float) -> None:\n            super().__init__()\n            self.dropout = nn.Dropout(dropout)\n            self.norm = LayerNormalization(features)\n    \n        def forward(self, x, sublayer):\n            return x + self.dropout(sublayer(self.norm(x)))\n\nclass MultiHeadAttentionBlock(nn.Module):\n\n    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n        super().__init__()\n        self.d_model = d_model # Embedding vector size\n        self.h = h # Number of heads\n        # Make sure d_model is divisible by h\n        assert d_model % h == 0, \"d_model is not divisible by h\"\n\n        self.d_k = d_model // h # Dimension of vector seen by each head\n        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n        self.dropout = nn.Dropout(dropout)\n\n    @staticmethod\n    def attention(query, key, value, mask, dropout: nn.Dropout):\n        d_k = query.shape[-1]\n        # Just apply the formula from the paper\n        # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n        if mask is not None:\n            # Write a very low value (indicating -inf) to the positions where mask == 0\n            attention_scores.masked_fill_(mask == 0, -1e9)\n        attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len) # Apply softmax\n        if dropout is not None:\n            attention_scores = dropout(attention_scores)\n        # (batch, h, seq_len, seq_len) --> (batch, h, seq_len, d_k)\n        # return attention scores which can be used for visualization\n        return (attention_scores @ value), attention_scores\n\n    def forward(self, q, k, v, mask):\n        query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n        key = self.w_k(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n        value = self.w_v(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n\n        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n\n        # Calculate attention\n        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n        \n        # Combine all the heads together\n        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n\n        # Multiply by Wo\n        # (batch, seq_len, d_model) --> (batch, seq_len, d_model)  \n        return self.w_o(x)\n\nclass EncoderBlock(nn.Module):\n\n    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n        super().__init__()\n        self.self_attention_block = self_attention_block\n        self.feed_forward_block = feed_forward_block\n        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n\n    def forward(self, x, src_mask):\n        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))\n        x = self.residual_connections[1](x, self.feed_forward_block)\n        return x\n    \nclass Encoder(nn.Module):\n\n    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n        super().__init__()\n        self.layers = layers\n        self.norm = LayerNormalization(features)\n\n    def forward(self, x, mask):\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)\n\nclass DecoderBlock(nn.Module):\n\n    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feed_forward_block: FeedForwardBlock, dropout: float) -> None:\n        super().__init__()\n        self.self_attention_block = self_attention_block\n        self.cross_attention_block = cross_attention_block\n        self.feed_forward_block = feed_forward_block\n        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])\n\n    def forward(self, x, encoder_output, src_mask, tgt_mask):\n        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n        x = self.residual_connections[2](x, self.feed_forward_block)\n        return x\n    \nclass Decoder(nn.Module):\n\n    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n        super().__init__()\n        self.layers = layers\n        self.norm = LayerNormalization(features)\n\n    def forward(self, x, encoder_output, src_mask, tgt_mask):\n        for layer in self.layers:\n            x = layer(x, encoder_output, src_mask, tgt_mask)\n        return self.norm(x)\n\nclass ProjectionLayer(nn.Module):\n\n    def __init__(self, d_model, vocab_size) -> None:\n        super().__init__()\n        self.proj = nn.Linear(d_model, vocab_size)\n\n    def forward(self, x) -> None:\n        # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n        return self.proj(x)\n    \nclass Transformer(nn.Module):\n\n    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.src_pos = src_pos\n        self.tgt_pos = tgt_pos\n        self.projection_layer = projection_layer\n\n    def encode(self, src, src_mask):\n        # (batch, seq_len, d_model)\n        src = self.src_embed(src)\n        src = self.src_pos(src)\n        return self.encoder(src, src_mask)\n    \n    def decode(self, encoder_output: torch.Tensor, src_mask: torch.Tensor, tgt: torch.Tensor, tgt_mask: torch.Tensor):\n        # (batch, seq_len, d_model)\n        tgt = self.tgt_embed(tgt)\n        tgt = self.tgt_pos(tgt)\n        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n    \n    def project(self, x):\n        # (batch, seq_len, vocab_size)\n        return self.projection_layer(x)\n    \ndef build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N: int=6, h: int=8, dropout: float=0.1, d_ff: int=2048) -> Transformer:\n    # Create the embedding layers\n    src_embed = InputEmbeddings(d_model, src_vocab_size)\n    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n\n    # Create the positional encoding layers\n    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n    \n    # Create the encoder blocks\n    encoder_blocks = []\n    for _ in range(N):\n        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n        encoder_block = EncoderBlock(d_model, encoder_self_attention_block, feed_forward_block, dropout)\n        encoder_blocks.append(encoder_block)\n\n    # Create the decoder blocks\n    decoder_blocks = []\n    for _ in range(N):\n        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n        feed_forward_block = FeedForwardBlock(d_model, d_ff, dropout)\n        decoder_block = DecoderBlock(d_model, decoder_self_attention_block, decoder_cross_attention_block, feed_forward_block, dropout)\n        decoder_blocks.append(decoder_block)\n    \n    # Create the encoder and decoder\n    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n    \n    # Create the projection layer\n    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n    \n    # Create the transformer\n    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n    \n    # Initialize the parameters\n    for p in transformer.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n    \n    return transformer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-02T10:51:46.491991Z","iopub.execute_input":"2024-06-02T10:51:46.492305Z","iopub.status.idle":"2024-06-02T10:51:50.969196Z","shell.execute_reply.started":"2024-06-02T10:51:46.492281Z","shell.execute_reply":"2024-06-02T10:51:50.967634Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\ndef get_config():\n    return {\n        \"batch_size\": 8,\n        \"num_epochs\": 20,\n        \"lr\": 10**-4,\n        \"seq_len\": 350,\n        \"d_model\": 512,\n        \"datasource\": 'opus_books',\n        \"lang_src\": \"en\",\n        \"lang_tgt\": \"it\",\n        \"model_folder\": \"weights\",\n        \"model_basename\": \"tmodel_\",\n        \"preload\": \"latest\",\n        \"tokenizer_file\": \"tokenizer_{0}.json\",\n        \"experiment_name\": \"runs/tmodel\"\n    }\n\ndef get_weights_file_path(config, epoch: str):\n    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n    model_filename = f\"{config['model_basename']}{epoch}.pt\"\n    return str(Path('.') / model_folder / model_filename)\n\n# Find the latest weights file in the weights folder\ndef latest_weights_file_path(config):\n    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n    model_filename = f\"{config['model_basename']}*\"\n    weights_files = list(Path(model_folder).glob(model_filename))\n    if len(weights_files) == 0:\n        return None\n    weights_files.sort()\n    return str(weights_files[-1])","metadata":{"execution":{"iopub.status.busy":"2024-06-02T10:52:13.474186Z","iopub.execute_input":"2024-06-02T10:52:13.475203Z","iopub.status.idle":"2024-06-02T10:52:13.483738Z","shell.execute_reply.started":"2024-06-02T10:52:13.475168Z","shell.execute_reply":"2024-06-02T10:52:13.482726Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\n\nclass BilingualDataset(Dataset):\n\n    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n        super().__init__()\n        self.seq_len = seq_len\n\n        self.ds = ds\n        self.tokenizer_src = tokenizer_src\n        self.tokenizer_tgt = tokenizer_tgt\n        self.src_lang = src_lang\n        self.tgt_lang = tgt_lang\n\n        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n\n    def __len__(self):\n        return len(self.ds)\n\n    def __getitem__(self, idx):\n        src_target_pair = self.ds[idx]\n        src_text = src_target_pair['translation'][self.src_lang]\n        tgt_text = src_target_pair['translation'][self.tgt_lang]\n\n        # Transform the text into tokens\n        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n\n        # Add sos, eos and padding to each sentence\n        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2  # We will add <s> and </s>\n        # We will only add <s>, and </s> only on the label\n        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1\n\n        # Make sure the number of padding tokens is not negative. If it is, the sentence is too long\n        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n            raise ValueError(\"Sentence is too long\")\n\n        # Add <s> and </s> token\n        encoder_input = torch.cat(\n            [\n                self.sos_token,\n                torch.tensor(enc_input_tokens, dtype=torch.int64),\n                self.eos_token,\n                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64),\n            ],\n            dim=0,\n        )\n\n        # Add only <s> token\n        decoder_input = torch.cat(\n            [\n                self.sos_token,\n                torch.tensor(dec_input_tokens, dtype=torch.int64),\n                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n            ],\n            dim=0,\n        )\n\n        # Add only </s> token\n        label = torch.cat(\n            [\n                torch.tensor(dec_input_tokens, dtype=torch.int64),\n                self.eos_token,\n                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n            ],\n            dim=0,\n        )\n\n        # Double check the size of the tensors to make sure they are all seq_len long\n        assert encoder_input.size(0) == self.seq_len\n        assert decoder_input.size(0) == self.seq_len\n        assert label.size(0) == self.seq_len\n\n        return {\n            \"encoder_input\": encoder_input,  # (seq_len)\n            \"decoder_input\": decoder_input,  # (seq_len)\n            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).int() & causal_mask(decoder_input.size(0)), # (1, seq_len) & (1, seq_len, seq_len),\n            \"label\": label,  # (seq_len)\n            \"src_text\": src_text,\n            \"tgt_text\": tgt_text,\n        }\n    \ndef causal_mask(size):\n    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n    return mask == 0","metadata":{"execution":{"iopub.status.busy":"2024-06-02T10:52:32.087283Z","iopub.execute_input":"2024-06-02T10:52:32.087934Z","iopub.status.idle":"2024-06-02T10:52:32.108383Z","shell.execute_reply.started":"2024-06-02T10:52:32.087904Z","shell.execute_reply":"2024-06-02T10:52:32.107325Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# from model import build_transformer\n# from dataset import BilingualDataset, causal_mask\n# from config import get_config, get_weights_file_path, latest_weights_file_path\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.optim.lr_scheduler import LambdaLR\n\nimport warnings\nfrom tqdm import tqdm\nimport os\nfrom pathlib import Path\n\n# Huggingface datasets and tokenizers\nfrom datasets import load_dataset\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import WordLevel\nfrom tokenizers.trainers import WordLevelTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\n\nimport torchmetrics\nfrom torch.utils.tensorboard import SummaryWriter\n\ndef greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n\n    # Precompute the encoder output and reuse it for every step\n    encoder_output = model.encode(source, source_mask)\n    # Initialize the decoder input with the sos token\n    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n    while True:\n        if decoder_input.size(1) == max_len:\n            break\n\n        # build mask for target so our model dont see future output\n        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n\n        # calculate output\n        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n\n        # get next token\n        prob = model.project(out[:, -1])\n        _, next_word = torch.max(prob, dim=1)\n        decoder_input = torch.cat(\n            [decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1\n        )\n\n        if next_word == eos_idx:\n            break\n\n    return decoder_input.squeeze(0)\n\n\ndef run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_step, writer, num_examples=2):\n    model.eval()\n    count = 0\n\n    source_texts = []\n    expected = []\n    predicted = []\n\n    try:\n        # get the console window width\n        with os.popen('stty size', 'r') as console:\n            _, console_width = console.read().split()\n            console_width = int(console_width)\n    except:\n        # If we can't get the console width, use 80 as default\n        console_width = 80\n\n    with torch.no_grad():\n        for batch in validation_ds:\n            count += 1\n            encoder_input = batch[\"encoder_input\"].to(device) # (b, seq_len)\n            encoder_mask = batch[\"encoder_mask\"].to(device) # (b, 1, 1, seq_len)\n\n            # check that the batch size is 1\n            assert encoder_input.size(\n                0) == 1, \"Batch size must be 1 for validation\"\n\n            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n\n            source_text = batch[\"src_text\"][0]\n            target_text = batch[\"tgt_text\"][0]\n            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n\n            source_texts.append(source_text)\n            expected.append(target_text)\n            predicted.append(model_out_text)\n            \n            # Print the source, target and model output\n            print_msg('-'*console_width)\n            print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n            print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n            print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n\n            if count == num_examples:\n                print_msg('-'*console_width)\n                break\n    \n    if writer:\n        # Evaluate the character error rate\n        # Compute the char error rate \n        metric = torchmetrics.CharErrorRate()\n        cer = metric(predicted, expected)\n        writer.add_scalar('validation cer', cer, global_step)\n        writer.flush()\n\n        # Compute the word error rate\n        metric = torchmetrics.WordErrorRate()\n        wer = metric(predicted, expected)\n        writer.add_scalar('validation wer', wer, global_step)\n        writer.flush()\n\n        # Compute the BLEU metric\n        metric = torchmetrics.BLEUScore()\n        bleu = metric(predicted, expected)\n        writer.add_scalar('validation BLEU', bleu, global_step)\n        writer.flush()\n\ndef get_all_sentences(ds, lang):\n    for item in ds:\n        yield item['translation'][lang]\n\ndef get_or_build_tokenizer(config, ds, lang):\n    tokenizer_path = Path(config['tokenizer_file'].format(lang))\n    if not Path.exists(tokenizer_path):\n        # Most code taken from: https://huggingface.co/docs/tokenizers/quicktour\n        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n        tokenizer.pre_tokenizer = Whitespace()\n        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n        tokenizer.save(str(tokenizer_path))\n    else:\n        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n    return tokenizer\n\ndef get_ds(config):\n    # It only has the train split, so we divide it overselves\n    ds_raw = load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n\n    # Build tokenizers\n    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n\n    # Keep 90% for training, 10% for validation\n    train_ds_size = int(0.9 * len(ds_raw))\n    val_ds_size = len(ds_raw) - train_ds_size\n    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n\n    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n\n    # Find the maximum length of each sentence in the source and target sentence\n    max_len_src = 0\n    max_len_tgt = 0\n\n    for item in ds_raw:\n        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n        max_len_src = max(max_len_src, len(src_ids))\n        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n\n    print(f'Max length of source sentence: {max_len_src}')\n    print(f'Max length of target sentence: {max_len_tgt}')\n    \n\n    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n\n    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n\ndef get_model(config, vocab_src_len, vocab_tgt_len):\n    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config['seq_len'], d_model=config['d_model'])\n    return model\n\ndef train_model(config):\n    # Define the device\n    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.has_mps or torch.backends.mps.is_available() else \"cpu\"\n    print(\"Using device:\", device)\n    if (device == 'cuda'):\n        print(f\"Device name: {torch.cuda.get_device_name(device.index)}\")\n        print(f\"Device memory: {torch.cuda.get_device_properties(device.index).total_memory / 1024 ** 3} GB\")\n    elif (device == 'mps'):\n        print(f\"Device name: <mps>\")\n    else:\n        print(\"NOTE: If you have a GPU, consider using it for training.\")\n        print(\"      On a Windows machine with NVidia GPU, check this video: https://www.youtube.com/watch?v=GMSjDTU8Zlc\")\n        print(\"      On a Mac machine, run: pip3 install --pre torch torchvision torchaudio torchtext --index-url https://download.pytorch.org/whl/nightly/cpu\")\n    device = torch.device(device)\n\n    # Make sure the weights folder exists\n    Path(f\"{config['datasource']}_{config['model_folder']}\").mkdir(parents=True, exist_ok=True)\n\n    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n    # Tensorboard\n    writer = SummaryWriter(config['experiment_name'])\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n\n    # If the user specified a model to preload before training, load it\n    initial_epoch = 0\n    global_step = 0\n    preload = config['preload']\n    model_filename = latest_weights_file_path(config) if preload == 'latest' else get_weights_file_path(config, preload) if preload else None\n    if model_filename:\n        print(f'Preloading model {model_filename}')\n        state = torch.load(model_filename)\n        model.load_state_dict(state['model_state_dict'])\n        initial_epoch = state['epoch'] + 1\n        optimizer.load_state_dict(state['optimizer_state_dict'])\n        global_step = state['global_step']\n    else:\n        print('No model to preload, starting from scratch')\n\n    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n\n    for epoch in range(initial_epoch, config['num_epochs']):\n        torch.cuda.empty_cache()\n        model.train()\n        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n        for batch in batch_iterator:\n\n            encoder_input = batch['encoder_input'].to(device) # (b, seq_len)\n            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n\n            # Run the tensors through the encoder, decoder and the projection layer\n            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n            proj_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n\n            # Compare the output with the label\n            label = batch['label'].to(device) # (B, seq_len)\n\n            # Compute the loss using a simple cross entropy\n            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n\n            # Log the loss\n            writer.add_scalar('train loss', loss.item(), global_step)\n            writer.flush()\n\n            # Backpropagate the loss\n            loss.backward()\n\n            # Update the weights\n            optimizer.step()\n            optimizer.zero_grad(set_to_none=True)\n\n            global_step += 1\n\n        # Run validation at the end of every epoch\n        run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n\n        # Save the model at the end of every epoch\n        model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'global_step': global_step\n        }, model_filename)\n\n\nif __name__ == '__main__':\n    warnings.filterwarnings(\"ignore\")\n    config = get_config()\n    train_model(config)","metadata":{"execution":{"iopub.status.busy":"2024-06-02T10:53:15.811051Z","iopub.execute_input":"2024-06-02T10:53:15.811406Z","iopub.status.idle":"2024-06-02T19:30:16.103598Z","shell.execute_reply.started":"2024-06-02T10:53:15.811379Z","shell.execute_reply":"2024-06-02T19:30:16.102743Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-06-02 10:53:22.619095: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-02 10:53:22.619234: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-02 10:53:22.782698: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nDevice name: Tesla T4\nDevice memory: 14.74810791015625 GB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/28.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53bf1a9f9cd54b0a83fc73f9a1cde462"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"755a5cb88ef443b186b54c406a1ea528"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/32332 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e5125606516496aa00ae38492989c29"}},"metadata":{}},{"name":"stdout","text":"Max length of source sentence: 309\nMax length of target sentence: 274\nNo model to preload, starting from scratch\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 00: 100%|██████████| 3638/3638 [25:43<00:00,  2.36it/s, loss=5.636]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: This put new thoughts into my head; for I presently imagined that these might be the men belonging to the ship that was cast away in the sight of my island, as I now called it; and who, after the ship was struck on the rock, and they saw her inevitably lost, had saved themselves in their boat, and were landed upon that wild shore among the savages. Upon this I inquired of him more critically what was become of them.\n    TARGET: Ciò suscitò nuovi pensieri nella mia mente; credei cioè appartener tali uomini al vascello naufragato a veggente della mia isola com’era solito chiamarla io; mi figurai che quando il vascello fu battuto contro allo scoglio e videro irreparabile la loro perdita, si fossero gettati nella scialuppa, approdando a qualunque rischio in quella terra selvaggia.\n PREDICTED: a , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e a a , e , e , e a a a , e , e , e , e , e , e , e , e , e a a a , e , e a , e , e , e , e , e , e , e , e , e , e , e , e , e , e a la mia la mia a a ,\n--------------------------------------------------------------------------------\n    SOURCE: \"Can you tell me where I could get employment of any kind?\" I continued.\n    TARGET: — Potete dirmi, — continuai, — dove potrei trovare un'occupazione qualsiasi?\n PREDICTED: — Non è vero , e io non vi ?\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 01: 100%|██████████| 3638/3638 [25:47<00:00,  2.35it/s, loss=4.972]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'Well, Agatha Mikhaylovna, is the jam done?' asked Levin, smiling at her and wishing to cheer her up. 'Has it turned out well the new way?'\n    TARGET: — Be’, Agaf’ja Michajlovna, è pronta la marmellata? — disse Levin, sorridendo ad Agaf’ja Michajlovna e desiderando rallegrarla. — Va bene col nuovo metodo?\n PREDICTED: — E , Dolly , Dolly ? — disse Levin , sorridendo , e Levin , sorridendo . — E il suo marito è stato stato stato ?\n--------------------------------------------------------------------------------\n    SOURCE: He was, apparently, a man who had tried everything.\n    TARGET: Era, si vedeva, un uomo che aveva provato tutto.\n PREDICTED: Egli era stato stato , ma il suo fratello era stato stato stato stato .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 02: 100%|██████████| 3638/3638 [25:47<00:00,  2.35it/s, loss=4.654]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: He would feel himself forsaken; his love rejected: he would suffer; perhaps grow desperate.\n    TARGET: Si sentirà abbandonato, crederà calpestato il suo amore, soffrirà e forse cadrà nella disperazione.\n PREDICTED: Egli voleva dire che la sua vita è stata buona , ma non poteva essere più .\n--------------------------------------------------------------------------------\n    SOURCE: Somehow, now that I had once crossed the threshold of this house, and once was brought face to face with its owners, I felt no longer outcast, vagrant, and disowned by the wide world. I dared to put off the mendicant--to resume my natural manner and character.\n    TARGET: Ora che avevo varcata la soglia di questa casa, che mi trovavo faccia a faccia con chi l'abitava, che non mi sentivo più respinta, vagabonda e disprezzata da tutti, cercai di spogliarmi dell'apparenza di mendicante e di riprendere il carattere e le maniere di prima.\n PREDICTED: Il signor Rochester mi era stato stato di nuovo , e mi sentii , e non avevo avuto la sua mano , ma non mi , e non mi la mia vita , e non mi la mia vita di .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 03: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=5.591]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: Plants will grow about your roots, whether you ask them or not, because they take delight in your bountiful shadow; and as they grow they will lean towards you, and wind round you, because your strength offers them so safe a prop.\"\n    TARGET: Nuove piante spunteranno intorno alle vostre radici, senza che voi glielo domandiate, perché saranno liete della vostra ricca ombra; s'appoggieranno con voi e vi cingeranno, perché la vostra forza sarà loro di sostegno.\n PREDICTED: a voi , se non vi , se non né la vostra ragione , e quando vi e e , e come un vento , e di .\n--------------------------------------------------------------------------------\n    SOURCE: 'For this reason,' Levin again interrupted him, 'that with electricity, you need only rub a piece of resin against wool, and you will always produce a certain phenomenon, but this other does not always act, so it is not a natural force.'\n    TARGET: — E perché — interruppe Levin — nel campo dell’elettricità, ogniqualvolta sfregate della resina contro della lana, si manifesta un determinato fenomeno; mentre qui non sempre si manifesta, dunque non si tratta di un fenomeno naturale.\n PREDICTED: — Ma questo non si può dire — disse Levin , — che tu hai fatto un ’ altra , un po ’ di , e un , e non si può essere , ma non è un uomo che non è un uomo che non è più più più più bello .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 04: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=5.490]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: Diana clapped her hands. \"That is just what we hoped and thought!\n    TARGET: Diana battè le mani. — È appunto quello che speravamo!\n PREDICTED: Diana , Maria , la sua mano è stata così contenta .\n--------------------------------------------------------------------------------\n    SOURCE: So she sat on, with closed eyes, and half believed herself in Wonderland, though she knew she had but to open them again, and all would change to dull reality--the grass would be only rustling in the wind, and the pool rippling to the waving of the reeds--the rattling teacups would change to tinkling sheep-bells, and the Queen's shrill cries to the voice of the shepherd boy--and the sneeze of the baby, the shriek of the Gryphon, and all the other queer noises, would change (she knew) to the confused clamour of the busy farm-yard--while the lowing of the cattle in the distance would take the place of the Mock Turtle's heavy sobs.\n    TARGET: Avrebbe sentito l'erba stormire al soffiar del vento, avrebbe veduto lo stagno incresparsi all'ondeggiare delle canne. L'acciottolio, delle tazze si sarebbe mutato nel tintinnio della campana delle pecore, e la stridula voce della Regina nella voce del pastorello, e gli starnuti del bimbo, l'urlo del Grifone e tutti gli altri curiosi rumori si sarebbero mutati (lei lo sapeva) nel rumore confuso d'una fattoria, e il muggito lontano degli armenti avrebbe sostituito i profondi singhiozzi della Falsa-testuggine.\n PREDICTED: E , guardando con gli occhi , si , e si sentiva , ma non sapeva che si fosse messo a , e si , e si , la testa , e la , la vecchia , e la , , la vecchia , la vecchia , la , la vecchia , la vecchia , la vecchia , e la , la vecchia , la , la , la vecchia , la vecchia , e la vecchia , la vecchia , e la testa , la vecchia , la testa , la , la testa , la vecchia , la vecchia , la vecchia , la vecchia , la testa , e la vecchia , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la vecchia , la testa , la vecchia , la vecchia , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la testa , la vecchia , la testa , la testa , la vecchia , la vecchia , la vecchia , la testa , la testa , la vecchia , la testa , la vecchia , la vecchia , la vecchia , la vecchia , la testa , la vecchia , la vecchia , la vecchia , la vecchia , la vecchia , la vecchia , la vecchia , la vecchia , la vecchia , la vecchia , la testa , la testa , la testa , la vecchia , la vecchia , la vecchia , la\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 05: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=4.928]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: Since then he had not heard any more of her.\n    TARGET: Da quel tempo non aveva mai più sentito parlare di lei.\n PREDICTED: E poi non aveva sentito parlare di lei .\n--------------------------------------------------------------------------------\n    SOURCE: Why, I wouldn't say anything about it, even if I fell off the top of the house!'\n    TARGET: Anche a cader dal tetto non mi farebbe nessun effetto!”\n PREDICTED: Perché non posso dire nulla , se non , se ne !\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 06: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=4.133]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: In the manner of my friend I was at once struck with an incoherence—an inconsistency; and I soon found this to arise from a series of feeble and futile struggles to overcome an habitual trepidancy—an excessive nervous agitation.\n    TARGET: Mi colpì, da bel principio, una certa incoerenza, una inconsistenza nelle maniere del mio amico e scoprii ben presto che ciò proveniva da uno sforzo incessante, – debole e puerile, – per vincere una trepidazione abituale, – un'eccessiva agitazione nervosa.\n PREDICTED: In quel momento la mia amica , ero in una specie di spirito , una strana impressione , e mi trovai di una certa importanza , e di quelle , di , di un ’ altra agitazione e di un ’ agitazione di .\n--------------------------------------------------------------------------------\n    SOURCE: The famous Medmenham monks, or \"Hell Fire Club,\" as they were commonly called, and of whom the notorious Wilkes was a member, were a fraternity whose motto was \"Do as you please,\" and that invitation still stands over the ruined doorway of the abbey.\n    TARGET: I famosi monaci di Medmenham, o il «Circolo del fuoco dell’inferno» com’erano chiamati, contavano tra le loro file il famoso Wilkes ed erano una confraternita il cui motto sanava: «Fate ciò che vi piace». L’esortazione ancora rimane sul diruto ingresso dell’Abbazia.\n PREDICTED: Il pianista nervoso , il , o le idee , — disse il quale erano , e , , — che , , un , un , e la vecchia porta , e la porta di , e la porta del quale si .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 07: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=3.407]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: CHAPTER XXIV\n    TARGET: XXIV\n PREDICTED: XXIV\n--------------------------------------------------------------------------------\n    SOURCE: The presence of Princess Tverskaya and the memories associated with her, coupled with the fact that he had never liked her, was unpleasant to Karenin, and he went straight to the nursery.\n    TARGET: La presenza della principessa Tverskaja, e per i ricordi legati a lei, e perché in complesso non gli era simpatica, non era gradita ad Aleksej Aleksandrovic, ed egli andò di filato nella camera dei bambini.\n PREDICTED: La presenza della principessa Tverskaja e della principessa con la propria abitudine , con la propria conoscenza , non era mai stata mai Aleksej Aleksandrovic , e Aleksej Aleksandrovic si era già spiacevole .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 08: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=3.529]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: 'We are holding the position, Sergius Ivanich!' said he, smoothing back his whiskers.\n    TARGET: — Occupiamo la posizione — disse, lisciandosi tutte e due le fedine — Sergej Ivanyc!\n PREDICTED: — la situazione , Sergej Ivanovic — disse , indicando i suoi baffi bianchi .\n--------------------------------------------------------------------------------\n    SOURCE: But even though he was resting from mental labours and was not writing, he was so used to mental activity that he liked expressing his thoughts in an elegant, concise style, and liked having a listener.\n    TARGET: Ma anche in vacanze, anche senza attendere, cioè, al proprio lavoro, egli era così abituato all’attività intellettuale, che amava esporre in bella e precisa forma le idee che gli venivano in mente, e amava che ci fosse qualcuno ad ascoltarle.\n PREDICTED: Ma pur avendo in modo di , non aveva ricevuto il denaro , era così evidente che , in particolare , in quel momento , aveva un ’ attività così grave , e con un ’ influenza d ’ un ’ azione , e , pur senza volere , si .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 09: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=3.309]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: Dolly was struck by the beauty of her head with locks of black hair which had escaped from under her top hat, her full shoulders and fine waist in the black riding-habit, and her whole quiet graceful bearing.\n    TARGET: La sua bella testa, con i capelli neri sfuggenti di sotto il cappello alto, le spalle piene, la vita sottile nell’amazzone nera, e la calma, aggraziata posizione in sella colpirono Dolly.\n PREDICTED: Dar ’ ja Aleksandrovna , la testa della bellezza della bellezza , con le spalle bianche , che aveva già , sotto le spalle larghe , sul cappello e i capelli neri e i capelli neri e i capelli neri , in particolare tutto , in particolare il suo aspetto , tutto , tutto il suo splendore di Dar ’ ja Aleksandrovna .\n--------------------------------------------------------------------------------\n    SOURCE: \"It is known that you are not my sister; I cannot introduce you as such: to attempt it would be to fasten injurious suspicions on us both.\n    TARGET: — Non si sa forse che non siete mia sorella? e che non posso farvi passar per tale?\n PREDICTED: — È strano che non siete mia sorella , e non posso darvi altro che voi il vostro interesse .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 10: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=3.491]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: \"No; you shall tear yourself away, none shall help you: you shall yourself pluck out your right eye; yourself cut off your right hand: your heart shall be the victim, and you the priest to transfix it.\"\n    TARGET: — Ti sbranerai da te, e nessuno ti aiuterà; ti strapperai l'occhio, ti strapperai la mano diritta; il cuore sarà la vittima e tu il carnefice.\n PREDICTED: — No , ; non avrete voluto ; a voi stessa la vostra mano ; il cuore per il cuore , la libertà e il prete .\n--------------------------------------------------------------------------------\n    SOURCE: 'But I think her hand will remain crooked all the same.'\n    TARGET: — Già ma io penso che il braccio resterà storto.\n PREDICTED: — Ma io penso , la mano .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 11: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=2.281]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: It was _my_ time to assume ascendency. _My_ powers were in play and in force.\n    TARGET: Ora stava a me a prendere l'ascendente. Le mie facoltà erano in giuoco ed ero piena di forze.\n PREDICTED: La campana della sala era stata data per . La forza era piena di forza .\n--------------------------------------------------------------------------------\n    SOURCE: 'With extras?' asked the Mock Turtle a little anxiously.\n    TARGET: — E avevate dei corsi facoltativi? — domandò la Falsa-testuggine con ansietà.\n PREDICTED: — Con l ' ? — domandò la Falsa - testuggine con un grido .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 12: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=2.818]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: \"I'll not stand you an inch in the stead of a seraglio,\" I said; \"so don't consider me an equivalent for one. If you have a fancy for anything in that line, away with you, sir, to the bazaars of Stamboul without delay, and lay out in extensive slave- purchases some of that spare cash you seem at a loss to spend satisfactorily here.\"\n    TARGET: — Non voglio tenervi davvero luogo di un serraglio, — dissi. — Se vi piace quel genere di donna, andate nei bazars di Stambul subito subito, e spendete, nel procurarvi schiave, quel denaro che non sapete impiegar qui.\n PREDICTED: — Non vi un poco per non esser buono , — risposi . — Non vi voglio , non mi credete per un ; avete una vagabonda , e per di quella , non per di esser costretta a , e voi sarete di .\n--------------------------------------------------------------------------------\n    SOURCE: This put my mother into a great passion; she told me she knew it would be to no purpose to speak to my father upon any such subject; that he knew too well what was my interest to give his consent to anything so much for my hurt; and that she wondered how I could think of any such thing after the discourse I had had with my father, and such kind and tender expressions as she knew my father had used to me; and that, in short, if I would ruin myself, there was no help for me; but I might depend I should never have their consent to it; that for her part she would not have so much hand in my destruction; and I should never have it to say that my mother was willing when my father was not.\n    TARGET: Egli sa troppo bene qual sia il tuo vero scopo per prestare giammai il suo assenso ad un partito di tanto tuo scapito; non capisco nemmeno come tu possa pensar tuttavia a cose di simil natura dopo il discorso di tuo padre, e dopo sì tenere ed amorose espressioni che adoperò teco; perchè io so qual discorso ti ha tenuto. Figliuolo caro, se vuoi rovinarti da te medesimo, non sarò io quella che t’aiuti a farlo; sta pur sicuro che l’assenso de’ tuoi genitori non l’otterrai in eterno.\n PREDICTED: Questo mio padre mi parlò in una specie di cortesia , ma mi disse che non sarebbe stato necessario a mio padre , che non a mio padre . Egli sapeva bene che cosa mi al mio discorso , e che mi per altro mio padre , e per quanto mi sarebbe piaciuto d ’ essere e per mio padre , e che la mia madre , e che avrei potuto di non essere , e che se fossi stata , non avrei saputo di , di , di , di , di mio padre , e di mio padre , di mio padre , di non di non di non essere suo padre , di me medesimo padre .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 13: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=3.055]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: One of the opposite arguments was his age.\n    TARGET: Sola considerazione sfavorevole era la propria età.\n PREDICTED: Uno dei suoi affari si era già sentito .\n--------------------------------------------------------------------------------\n    SOURCE: She gave him her hand, and with her quick elastic step went past the hall-porter and vanished into the carriage.\n    TARGET: Gli tese la mano, e col passo svelto ed elastico passò accanto al portiere e scomparve nella carrozza.\n PREDICTED: Ella gli diede la mano e con tutta la sua andatura inquieta , e il portiere che veniva fuori era in carrozza .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 14: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=3.339]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: \"Not a great deal, to be sure,\" agreed Bessie: \"at any rate, a beauty like Miss Georgiana would be more moving in the same condition.\" \"Yes, I doat on Miss Georgiana!\" cried the fervent Abbot.\n    TARGET: — È vero, — rispose Bessie esitando, — è certo che una bellezza come la signorina Georgiana vi commoverebbe più, se fosse nella stessa posizione. — Sì, — esclamò l'ardente Abbot, — tengo per la signorina Georgiana!\n PREDICTED: — Non molto ; è facile ; Adele ha potuto essere così ; la signorina Temple avrebbe continuato a sopportare il suo stato in cui era vicina ; ho fatto la signorina Temple !\n--------------------------------------------------------------------------------\n    SOURCE: She went out, slamming the door.\n    TARGET: E uscì, sbattendo la porta.\n PREDICTED: Ella uscì dalla porta , .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 15: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=2.552]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: And it is seen that his foundations were good, for the Romagna awaited him for more than a month. In Rome, although but half alive, he remained secure; and whilst the Baglioni, the Vitelli, and the Orsini might come to Rome, they could not effect anything against him. If he could not have made Pope him whom he wished, at least the one whom he did not wish would not have been elected.\n    TARGET: E ch'e' fondamenti sua fussino buoni, si vidde: ché la Romagna l’aspettò più d’uno mese; in Roma, ancora che mezzo vivo, stette sicuro; e benché Ballioni, Vitelli et Orsini venissino in Roma, non ebbono séguito contro di lui: possé fare, se non chi e' volle papa, almeno che non fussi chi non voleva.\n PREDICTED: E li vide che li sua buoni cavalli , per un mese , per un mese , in cui , in mezzo a Roma ; ma , vedendo che , a ' cavalli , e li quali , non poteva lasciare a Roma , e non si poteva trovare el papa , perché non poteva trovare el papa con quella gente che era .\n--------------------------------------------------------------------------------\n    SOURCE: To settle the dispute, we appealed to the boy. We told him not to be afraid, but to speak the plain truth: Was it the fossil of a pre-Adamite whale, or was it an early Roman coffin?\n    TARGET: A metter fine alla disputa, ci appellammo al ragazzo, avvertendolo di non aver paura, ma di dire la semplice verità: — era il fossile d’una balena preadamitica, o un feretro di Roma primitiva?\n PREDICTED: A ogni modo , noi il ragazzo ; noi non lo a meno ; ma a quanto si faceva parlare del male dello steccato che si sia reso da una parte civile , o se ne fosse una assegnata .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 16: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=2.672]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: At the close of the afternoon service we returned by an exposed and hilly road, where the bitter winter wind, blowing over a range of snowy summits to the north, almost flayed the skin from our faces.\n    TARGET: Dopo il servizio della sera si tornava per una strada scoscesa. Il vento del nord soffiava con tanta forza da tagliarci la faccia.\n PREDICTED: Alla metà del pomeriggio , dopo aver sospirato , che meno ore di nebbia che il vento , intorno a noi , la nostra vita , di , di non .\n--------------------------------------------------------------------------------\n    SOURCE: 'Oh, yes, you saved that Levin from unpleasantness.'\n    TARGET: — Come! Avete salvato quel Levin da un incidente increscioso.\n PREDICTED: — Ah , sì , voi avete da Mosca per l ’ azienda .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 17: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=2.787]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: And that you should hire horses in the village is, in the first place, unpleasant to me, and besides that, they will undertake the job but won't get you there.\n    TARGET: E poi, prenderli in affitto al paese, in primo luogo mi rincresce, e poi anche se prenderanno l’incarico, non ti porteranno fin là.\n PREDICTED: E voi , ecco i cavalli , i primi posti al primo posto , e soprattutto , secondo il primo , mi dirà che non vi siate venuto , ma che vi .\n--------------------------------------------------------------------------------\n    SOURCE: 'Now confess that you feel like the bridegroom in Gogol's play who jumped out of the window?' teased Chirikov.\n    TARGET: — Ma, dite la verità, non avete la sensazione, come lo sposo di Gogol’ d’aver voglia di saltar via dalla finestra?\n PREDICTED: — E allora , hai preso lo stesso favore , dove si fa girare la finestra ? — chiese cirikov , a fianco .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 18: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=2.173]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: Maidenhead itself is too snobby to be pleasant.\n    TARGET: Maidenhead si dà troppe arie per esser simpatica.\n PREDICTED: Per questo è troppo piacevole per lei .\n--------------------------------------------------------------------------------\n    SOURCE: It was not without a certain wild pleasure I ran before the wind, delivering my trouble of mind to the measureless air-torrent thundering through space.\n    TARGET: Provavo un piacere selvaggio a correre sotto il vento e a stordire il mio spirito conturbato, in mezzo a quel torrente d'aria, che ruggiva da ogni lato.\n PREDICTED: Non era un piacere che mi sentii prima di aver prima fatto il vento in cui mi aveva fatto l ’ aria di il più .\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Processing Epoch 19: 100%|██████████| 3638/3638 [25:46<00:00,  2.35it/s, loss=1.763]\nstty: 'standard input': Inappropriate ioctl for device\n","output_type":"stream"},{"name":"stdout","text":"--------------------------------------------------------------------------------\n    SOURCE: This captain taking a fancy to my conversation, which was not at all disagreeable at that time, hearing me say I had a mind to see the world, told me if I would go the voyage with him I should be at no expense; I should be his messmate and his companion; and if I could carry anything with me, I should have all the advantage of it that the trade would admit; and perhaps I might meet with some encouragement.\n    TARGET: Egli prese diletto alla mia conversazione che non era in quel tempo affatto disaggradevole, e udito da me che avea voglia di vedere il mondo, mi disse: — «Se vi piacesse di venire in mia compagnia, non dovreste soggiacere a veruna spesa; sareste il mio commensale e compagno; e se poteste portare qualche merce con voi, ne ritrarreste tutti quei vantaggi che può offrire il commercio; e tali forse da vedervi incoraggiato a maggiori cose in appresso.»\n PREDICTED: Ciò mi diede l ’ intenzione di non vedermi affatto in cui non era stato affatto piacevole a comprendere , che il mio m ’ era stato in mente , se fossi andato in società al mondo , avrei voluto venire con me in suo figlio . Se fossi stato io stato cattivo e non avrei posto una compagna di ; avrei avuto torto nel Brasile .\n--------------------------------------------------------------------------------\n    SOURCE: It looks so peaceful and so quiet, and it is such a dear old place to ramble round in the early morning before many people are about.\n    TARGET: Sembra così cheto e tranquillo, ed è un così caro recesso da vagarvi la mattina presto, prima che molta gente sia in giro.\n PREDICTED: La stessa cosa è così calma , e così è una vecchia di quella mattina con gli amici che ci sono in maggior parte .\n--------------------------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}